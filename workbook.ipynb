{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1eba6900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import logging\n",
    "\n",
    "from nltk.corpus import wordnet, words, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger_eng', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('words', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "694759cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and Patterns\n",
    "\n",
    "# Regex for matching roman numerals\n",
    "ROMAN_NUMERAL_PATTERN = re.compile(\n",
    "    r'^(M{0,3})(CM|CD|D?C{0,3})'\n",
    "    r'(XC|XL|L?X{0,3})(IX|IV|V?I{0,3})$', re.IGNORECASE\n",
    ")\n",
    "\n",
    "# Spelled-out numbers\n",
    "SPELLED_NUMBERS = [\n",
    "    \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"ten\",\n",
    "    \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\", \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\", \"twenty\",\n",
    "    \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\",\n",
    "    \"hundred\", \"thousand\", \"million\", \"billion\"\n",
    "]\n",
    "\n",
    "SPELLED_NUMBERS += ['first', 'second', 'third', 'fourth', 'fifth', 'sixth', 'seventh', 'eighth', 'ninth', 'tenth']\n",
    "SPELLED_NUMBERS += ['eleventh', 'twelfth', 'thirteenth', 'fourteenth', 'fifteenth', 'sixteenth', 'seventeenth', 'eighteenth', 'nineteenth']\n",
    "SPELLED_NUMBERS += ['twentieth', 'thirtieth', 'fortieth', 'fiftieth', 'sixtieth', 'seventieth', 'eightieth', 'ninetieth']\n",
    "SPELLED_NUMBERS += ['hundredth', 'thousandth', 'millionth', 'billionth']\n",
    "\n",
    "SPELLED_NUMBERS += ['twice', 'thrice', 'once']\n",
    "SPELLED_NUMBERS += ['single', 'double', 'triple', 'quadruple', 'quintuple', 'sextuple', 'septuple', 'octuple', 'nonuple', 'decuple']\n",
    "SPELLED_NUMBERS += ['dozen', 'fortnight', 'score', 'century', 'millennium']\n",
    "\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "ENGLISH_VOCAB = set(w.lower() for w in words.words())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "ba9075e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# File functions\n",
    "# Load JSON data from a file\n",
    "def load_json_data(file_path):\n",
    "    try:\n",
    "        data = pd.read_json(file_path, orient=\"records\", lines=False)\n",
    "        return data\n",
    "    except ValueError as e:\n",
    "        print(f\"Error loading JSON data: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def strip_html_tags(text):\n",
    "    \"\"\"\n",
    "    Strips HTML tags from a string.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input string potentially containing HTML tags.\n",
    "\n",
    "    Returns:\n",
    "        str: The string with HTML tags removed.\n",
    "    \"\"\"\n",
    "    # Regex to find any HTML tag: < followed by any characters, then >\n",
    "    # The '?' makes it non-greedy, matching the shortest possible string.\n",
    "    # The '|' handles self-closing tags like <br/> or <img src=\"...\">\n",
    "    # and also comments (though less common in user-generated text usually)\n",
    "    clean = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    return re.sub(clean, '', text)\n",
    "\n",
    "def strip_quotes(text):\n",
    "    \"\"\"\n",
    "    Strips quotes only if it appears at the start and end of the argument text.\n",
    "    \"\"\"\n",
    "    if text.startswith('\"') and text.endswith('\"'):\n",
    "        return text[1:-1]\n",
    "    elif text.startswith(\"'\") and text.endswith(\"'\"):\n",
    "        return text[1:-1]\n",
    "    return text\n",
    "\n",
    "def is_valid_roman(string):\n",
    "    \"\"\"\n",
    "    Checks if the input text is a valid Roman numeral.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input string to check.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the text is a valid Roman numeral, False otherwise.\n",
    "    \"\"\"\n",
    "    return bool(ROMAN_NUMERAL_PATTERN.match(string))\n",
    "\n",
    "def is_noun_roman_bigram(bigram):\n",
    "    \"\"\"\n",
    "    Checks if the bigram contains a valid Roman numeral and a noun.\n",
    "\n",
    "    Args:\n",
    "        bigram (tuple): A tuple containing two words (bigram).\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the first word is a valid Roman numeral and the second word is a noun, False otherwise.\n",
    "    \"\"\"\n",
    "    return is_noun(bigram[0]) and is_valid_roman(bigram[1])\n",
    "\n",
    "def find_valid_roman_numerals(input_text, debug=False):\n",
    "    \"\"\"\n",
    "    Parses the input text to find and return valid Roman numerals.\n",
    "\n",
    "    Args:\n",
    "        input_text (str): The input string to parse.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of valid Roman numerals found in the input text.\n",
    "    \"\"\"\n",
    "    # Split the input text into words\n",
    "    # input_tokens = nltk.word_tokenize(input_text)\n",
    "    input_tokens = input_text.split()\n",
    "    valid_roman_numerals = []\n",
    "\n",
    "    for idx in range(len(input_tokens)):\n",
    "        # Check if the word is a valid Roman numeral\n",
    "        if debug:\n",
    "            print(f\"Checking token: {input_tokens[idx]} at index {idx}\")\n",
    "        \n",
    "        # If entire token is not uppercase, skip it\n",
    "        if not input_tokens[idx].isupper():\n",
    "            continue\n",
    "\n",
    "        if len(input_tokens[idx]) <= 2:\n",
    "            if idx == 0:\n",
    "                continue  # Short words at the start are likely not valid Roman numerals\n",
    "\n",
    "            first_word, second_word = input_tokens[idx-1], input_tokens[idx]\n",
    "            # If first word ends in comma or period, skip it\n",
    "            if first_word.endswith((',', '.', ';', ':')):\n",
    "                if debug:\n",
    "                    print(f\"Skipping due to punctuation: {first_word}\")\n",
    "                continue\n",
    "\n",
    "            # Remove any symbols from first word\n",
    "            first_word = re.sub(r'[^\\w\\s]', '', first_word)\n",
    "\n",
    "            # Check if previous word is a noun followed by a valid Roman numeral\n",
    "            if is_noun_roman_bigram((first_word, second_word)):\n",
    "                # If the previous word is a noun and the current word is a valid Roman numeral\n",
    "                if debug:\n",
    "                    print(f\"Found valid Roman numeral: {first_word} {second_word} -- adding {input_tokens[idx]}\")\n",
    "                valid_roman_numerals.append(input_tokens[idx])\n",
    "        else: \n",
    "            if is_valid_roman(input_tokens[idx]):\n",
    "                valid_roman_numerals.append(input_tokens[idx])\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Original input: {input_text}\")\n",
    "        print(f\"Valid Roman numerals found: {valid_roman_numerals}\")\n",
    "\n",
    "    \n",
    "    # Filter and return only valid Roman numerals\n",
    "    return valid_roman_numerals\n",
    "\n",
    "def is_noun(word):\n",
    "    # NLTK POS tagger expects a list of tokens\n",
    "    pos = nltk.pos_tag([word])[0][1]\n",
    "    # Nouns in Penn Treebank tagset start with 'NN'\n",
    "    return pos.startswith('NN')\n",
    "\n",
    "\n",
    "def find_non_english_word(input_text, filter=\"wordnet\", stopword_list=STOPWORDS, lemmatizer=lemmatizer, debug=False):\n",
    "    \"\"\"\n",
    "        Finds non-English words in the input text using POS tagging and lemmatization.\n",
    "\n",
    "        Args:\n",
    "            input_text (str): The input string to parse.\n",
    "            filter (str, optional): Method to determine English words. \n",
    "                \"wordnet\" uses WordNet synsets, \"dict\" uses ENGLISH_VOCAB. Default is \"wordnet\".\n",
    "            stopword_list (set, optional): Set of stopwords to ignore. Default is STOPWORDS.\n",
    "            lemmatizer (WordNetLemmatizer, optional): Lemmatizer for reducing words to base form. Default is lemmatizer.\n",
    "            debug (bool, optional): If True, prints debug information. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of non-English words found in the input text.\n",
    "        \"\"\"\n",
    "    # Tags only used for tagged-based filtering\n",
    "    function_tags = ['NNP', 'NNPS', 'IN', 'DT', 'WP', 'WP$', 'WRB', 'PRP', 'PRP$', 'CC', 'TO', 'MD', 'EX', 'UH']\n",
    "\n",
    "    # Tokenize and POS tag the full sentence\n",
    "    input_tokens = nltk.word_tokenize(input_text)\n",
    "    tagged_tokens = nltk.pos_tag(input_tokens)\n",
    "\n",
    "    # Filter out tokens that are not alphabetic or are stopwords or have a function tag\n",
    "    filtered_tokens = [\n",
    "        (word, tag) for word, tag in tagged_tokens\n",
    "        if word.isalpha() and word.lower() not in stopword_list and tag not in function_tags\n",
    "    ]\n",
    "\n",
    "    non_english_words = []\n",
    "    for word, tag in filtered_tokens:\n",
    "        lemma_word = lemmatizer.lemmatize(word.lower())\n",
    "        if filter == \"wordnet\" and not wordnet.synsets(lemma_word):\n",
    "            non_english_words.append(word)\n",
    "        elif filter == \"dict\" and not (lemma_word in ENGLISH_VOCAB or word.lower() in ENGLISH_VOCAB):\n",
    "            non_english_words.append(word)\n",
    "\n",
    "        if debug:\n",
    "            print(f\"Word: {word}, Tag: {tag}, Lemma: {lemma_word}, Is English: {bool(wordnet.synsets(lemma_word))}\")\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Original input: {input_text}\")\n",
    "        print(f\"Non-English words found: {non_english_words}\")\n",
    "\n",
    "    return non_english_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "fdfd8d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: soccer, Tag: NN, Lemma: soccer, Is English: True\n",
      "Word: player, Tag: NN, Lemma: player, Is English: True\n",
      "Word: real, Tag: JJ, Lemma: real, Is English: True\n",
      "Word: first, Tag: JJ, Lemma: first, Is English: True\n",
      "Word: name, Tag: NN, Lemma: name, Is English: True\n",
      "Word: one, Tag: CD, Lemma: one, Is English: True\n",
      "Word: women, Tag: NNS, Lemma: woman, Is English: True\n",
      "Word: scored, Tag: VBN, Lemma: scored, Is English: True\n",
      "Word: goals, Tag: NNS, Lemma: goal, Is English: True\n",
      "Word: international, Tag: JJ, Lemma: international, Is English: True\n",
      "Word: play, Tag: NN, Lemma: play, Is English: True\n",
      "Original input: This soccer player whose real first name is Mariel is one of 4 women to have scored over 100 goals in international play.\n",
      "Non-English words found: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_non_english_word(\"This soccer player whose real first name is Mariel is one of 4 women to have scored over 100 goals in international play.\", debug=True)\n",
    "\n",
    "# nltk.pos_tag(['Richard'])[0][1] == 'NNP'\n",
    "\n",
    "# lemmatizer.lemmatize('praciticing', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "152d9fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "JSON_FILE_PATH = './dataset/JEOPARDY_QUESTIONS1.json'\n",
    "df = load_json_data(JSON_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f66002ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-cleaning steps\n",
    "\n",
    "# create copy of question to original_question\n",
    "df['original_question'] = df['question'].copy()\n",
    "\n",
    "# Strip HTML tags from the 'question' column\n",
    "df['question'] = df['question'].apply(strip_html_tags)\n",
    "\n",
    "# Strip quotes from the 'question' column\n",
    "df['question'] = df['question'].apply(strip_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5fab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for spelled numbers in the 'question' column\n",
    "df['has_spelled_number'] = df['question'].apply(\n",
    "    lambda x: any(word in SPELLED_NUMBERS for word in nltk.word_tokenize(x.lower()))\n",
    ")\n",
    "\n",
    "# Extract roman numerals in the 'question' column\n",
    "df['roman_text'] = df['question'].apply(\n",
    "    lambda x: find_valid_roman_numerals(x)\n",
    ")\n",
    "df['has_roman_numeral'] = df['roman_text'].apply(\n",
    "    lambda x: len(x) > 0\n",
    ")\n",
    "\n",
    "# Check for numerical values in the 'question' column\n",
    "df['has_numerical_value'] = df['question'].apply(\n",
    "    lambda x: any(re.search(r'\\d', token) for token in nltk.word_tokenize(x))\n",
    ")\n",
    "\n",
    "# has_number \n",
    "df['has_number'] = df['has_spelled_number'] | df['has_numerical_value'] | df['has_roman_numeral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d5d96a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample questions with spelled numbers:\n",
      "173009. Category: GOING HORSE, Question: This capital of Canada's Yukon Territory was once home to the world's largest Tungsten reserve\n",
      "162543. Category: SPEAK UP!, Question: An Irish wit & playwright:\"Bigamy is having one wife too many.  Monogamy is the same\"\n",
      "180058. Category: MAGAZINES, Question: Yachting magazine celebrates its 100th anniversary in 2007; the first issue featured an article by this tea merchant\n",
      "75069. Category: & NEVER THE TWAINS SHALL MEET, Question: Mark first visited this city in 1872; in 1999 Shania played the Prince's Trust concert in Hyde Park there\n",
      "151329. Category: LOTTO FEVER, Question: 13 workers at one of this coffee chain's stores in California became stars when they won big bucks in 2000...$87 million\n",
      "Sample questions with roman numerals:\n",
      "126213. Category: FELONIOUS MONKS, Question: In 1589 a fanatical monk named Jacques Clement assassinated this country's reigning King Henry III\n",
      "163639. Category: BALLET, Question: Act I of this Tchaikovsky ballet is called \"The Spell\"\n",
      "112331. Category: GRIDIRON GREATS, Question: (Hi, I'm Curtis Conway of the Chicago Bears)  I joined the Bears in 1993, so I just missed the pleasure of playing with this legendary coach\n",
      "168316. Category: POETS & POETRY, Question: Kipling called this regimental water-carrier \"The finest man I knew\"\n",
      "82797. Category: HISTORIC NICKNAMES, Question: The 7th Century's Constantine V Copronymus, monarch of this Eastern empire, was known as \"The Ill-Odored\"\n",
      "Sample questions with numerical values:\n",
      "75615. Category: HISTORIC NAMES, Question: On June 27, 1525 he married former nun Katherine von Bora\n",
      "27847. Category: THE 19th CENTURY, Question: This pair of printmakers began their very lucrative partnership in 1857\n",
      "55543. Category: ELVIS FILM ROLES, Question: 1957:Vince Everett, who serves time for manslaughter\n",
      "68162. Category: COW, Question: One of the 2 breeds of milk cows named for English Channel islands\n",
      "42684. Category: IMAGINARY RACES, Question: Doozers were builders & Gorgs were giants, 7 times bigger than these furry beings created for TV by Jim Henson\n"
     ]
    }
   ],
   "source": [
    "# Output samples of spelling numbers\n",
    "print(\"Sample questions with spelled numbers:\")\n",
    "sample_list = df[df['has_spelled_number']].sample(5)[['category', 'question']]\n",
    "\n",
    "for idx, row in sample_list.iterrows():\n",
    "    print(f\"{idx}. Category: {row['category']}, Question: {row['question']}\")\n",
    "\n",
    "# Output samples of roman numerals\n",
    "print(\"Sample questions with roman numerals:\")\n",
    "sample_list = df[df['has_roman_numeral']].sample(5)[['category', 'question']]\n",
    "for idx, row in sample_list.iterrows():\n",
    "    print(f\"{idx}. Category: {row['category']}, Question: {row['question']}\")\n",
    "\n",
    "# Output samples of numerical values\n",
    "print(\"Sample questions with numerical values:\")\n",
    "sample_list = df[df['has_numerical_value']].sample(5)[['category', 'question']]\n",
    "for idx, row in sample_list.iterrows():\n",
    "    print(f\"{idx}. Category: {row['category']}, Question: {row['question']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "486ac829",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['non_english_words'] = df['question'].apply(\n",
    "    lambda x: find_non_english_word(x)\n",
    ")\n",
    "\n",
    "df['has_non_english_word'] = df['non_english_words'].apply(\n",
    "    lambda x: len(x) > 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "cb3d0ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample questions with non-English words:\n",
      "154842. Q: This name of an airport runway surface comes from a substance in it & inventor McAdam, Non-EN: ['McAdam']\n",
      "99382. Q: Like some gouramis, several grunts are famous for doing this when 2 of them meet, Non-EN: ['gouramis']\n",
      "168539. Q: It's where Finns traditionally go to feel the loyly, \"steam heat\", & get hikinen, \"sweaty\", Non-EN: ['loyly', 'hikinen', 'sweaty']\n",
      "207978. Q: In 787, during Pope Adrian I's reign, the 2nd Council of this \"creed\" city tried to resolve the iconoclatic controversy, Non-EN: ['iconoclatic']\n",
      "88900. Q: \"Please, Lily, understand, everything I did was to keep you and the twins safe.\"\"Cane, you pretended that you were dead and made me think that I was sleeping with a ghost.  I ended up in an insane asylum.  You're...\"...this 10-letter adjective from the Latin for \"look down on\" (& favored by Daffy Duck on occasion), Non-EN: ['everything']\n",
      "34014. Q: Phoenix's firefighting museum isn't called the Hall of Fame but the Hall of this, Non-EN: ['firefighting']\n",
      "134023. Q: You might take due aspirina if you have un mal di capo, one of these, Non-EN: ['aspirina', 'mal', 'di']\n",
      "196005. Q: Ralph Lauren gained fame in the late '60s with this sporty menswear line, Non-EN: ['menswear']\n",
      "31201. Q: During WWII, Marshall Henri Petain headed the Vichy gov’t while this man led the Free French, Non-EN: ['gov']\n",
      "170759. Q: OK chums, Deathwing the Dragon has caused a \"cataclysm\" on Azeroth in a 2010 expansion of this massive game, Non-EN: ['Deathwing']\n"
     ]
    }
   ],
   "source": [
    "# Show sample questions with non-English words\n",
    "print(\"Sample questions with non-English words:\")\n",
    "sample_list = df[df['has_non_english_word']].sample(10)[['category', 'question', 'non_english_words']]\n",
    "for idx, row in sample_list.iterrows():\n",
    "    print(f\"{idx}. Q: {row['question']}, Non-EN: {row['non_english_words']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "bd390de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: understand, Tag: NN, Lemma: understand, Is English: True\n",
      "Word: everything, Tag: NN, Lemma: everything, Is English: False\n",
      "Word: keep, Tag: VB, Lemma: keep, Is English: True\n",
      "Word: twins, Tag: NNS, Lemma: twin, Is English: True\n",
      "Word: safe, Tag: JJ, Lemma: safe, Is English: True\n",
      "Word: pretended, Tag: VBD, Lemma: pretended, Is English: True\n",
      "Word: dead, Tag: JJ, Lemma: dead, Is English: True\n",
      "Word: made, Tag: VBD, Lemma: made, Is English: True\n",
      "Word: think, Tag: VB, Lemma: think, Is English: True\n",
      "Word: sleeping, Tag: VBG, Lemma: sleeping, Is English: True\n",
      "Word: ghost, Tag: NN, Lemma: ghost, Is English: True\n",
      "Word: ended, Tag: VBD, Lemma: ended, Is English: True\n",
      "Word: insane, Tag: NN, Lemma: insane, Is English: True\n",
      "Word: asylum, Tag: NN, Lemma: asylum, Is English: True\n",
      "Word: adjective, Tag: NN, Lemma: adjective, Is English: True\n",
      "Word: look, Tag: VB, Lemma: look, Is English: True\n",
      "Word: favored, Tag: VBN, Lemma: favored, Is English: True\n",
      "Word: occasion, Tag: NN, Lemma: occasion, Is English: True\n",
      "Original input: \"Please, Lily, understand, everything I did was to keep you and the twins safe.\"\"Cane, you pretended that you were dead and made me think that I was sleeping with a ghost.  I ended up in an insane asylum.  You're...\"...this 10-letter adjective from the Latin for \"look down on\" (& favored by Daffy Duck on occasion)\n",
      "Non-English words found: ['everything']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['everything']"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if 'richard' is nnp\n",
    "\"everything\" in ENGLISH_VOCAB\n",
    "# nltk.pos_tag(['Run'])[0][1] == 'NNP'\n",
    "\n",
    "find_non_english_word(df.iloc[88900].question, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
